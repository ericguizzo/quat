{
  "global_parameters":{
        "gpu_id":1,
        "experiment_description": "no_beta_no_batchnorm_fasetest",
        "script": "training_autoencoder_simple.py",
        "dataset": "iemocap",
        "num_experiment": 14,
        "num_folds": 1,
        "num_epochs": 200000,
        "learning_rate": 0.000001,
        "batch_size": 50,
        "model_name": "simple_autoencoder",
        "fast_test": "False",
        "load_pretrained": "'../new_experiments/experiment_15_pretraining_reconstruction.txt/models/model_xval_iemocap_exp15_pretraining_reconstruction.txt_run1_fold0'"
,
        "patience": 100,
        "save_model_metric": "total_loss",
        "early_stopping": "True",
        "model_quat": "True",
        "time_dim":512,
        "model_architecture":"VGG16"
      },

  "1":{"comment_1": "beta_0.01", "comment_2": "warm_10_holes_2",
       "loss_beta": 0.01, "emo_loss_holes": 2,
       "emo_loss_warmup_epochs": 20, "regularization_lambda":0.00001
        },
  "2":{"comment_1": "reg_0.001", "comment_2": "warm_10_holes_2",
       "loss_beta": 0.01, "emo_loss_holes": 2,
       "emo_loss_warmup_epochs": 20, "regularization_lambda":0.001
        },
  "3":{"comment_1": "reg_0.001_beta1", "comment_2": "warm_10_holes_2",
       "loss_beta": 1, "emo_loss_holes": 2,
       "emo_loss_warmup_epochs": 20, "regularization_lambda":0.00001
        },
  "4":{"comment_1": "reg_0.001_beta1", "comment_2": "warm_10_holes_0",
       "loss_beta": 1,
       "emo_loss_warmup_epochs": 20, "regularization_lambda":0.00001
        },
  "5":{"comment_1": "beta10", "comment_2": "warm_10_holes_2",
       "loss_beta": 10, "emo_loss_holes": 2,
       "emo_loss_warmup_epochs": 20, "regularization_lambda":0.00001
        },
  "6":{"comment_1": "beta10", "comment_2": "warm_10_holes_3",
       "loss_beta": 10, "emo_loss_holes": 3,
       "emo_loss_warmup_epochs": 20, "regularization_lambda":0.00001
        }
}
