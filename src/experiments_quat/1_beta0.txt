{
  "global_parameters":{
        "gpu_id":0,
        "experiment_description": "no beta",
        "script": "training_autoencoder.py",
        "dataset": "iemocap",
        "num_experiment": 0,
        "num_folds": 1,
        "num_epochs": 1,
        "learning_rate": 0.000001,
        "batch_size": 5,
        "model_name": "r2he",
        'fast_test': "False"
      },

  "1":{"comment_1": "beta 0", "comment_2": "no emo",
       "model_beta": "0",
        },
  "2":{"comment_1": "pretrain on ", "comment_2": "bla"
      },

}
