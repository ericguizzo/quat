{
  "global_parameters":{
        "gpu_id":1,
        "experiment_description": "testing_vgg",
        "script": "training_emotion_recognition.py",
        "dataset": "iemocap",
        "num_experiment": 24,
        "num_folds": 1,
        "num_epochs": 2,
        "learning_rate": 0.001,
        "batch_size": 20,
        "model_name": "VGGNet",
        "fast_test": "True",
        "r2he_model_path": "'../new_experiments/experiment_23_betagrid_RIPARTO.txt/models/model_xval_iemocap_exp23_betagrid_RIPARTO.txt_run1_fold0'",

        "patience": 30,
        "save_model_metric": "loss",
        "early_stopping": "True",
        "time_dim":512,
        "spreadsheet_profile": "profile_emotion_recognition"
      },


  "1":{"comment_1": "baseline", "comment_2": "no_r2he_real",
        "use_r2he":"False",
        "model_quat":"False"
        },
  "2":{"comment_1": "r2he", "comment_2": "feat_recon",
        "use_r2he":"True",
        "model_quat":"True",
        "r2he_features_type":"reconstruction"
        },
  "3":{"comment_1": "r2he", "comment_2": "feat_embeddings",
        "use_r2he":"True",
        "model_quat":"True",
        "r2he_features_type":"embeddings",
        "model_flatten_dim":2048
        }

}
